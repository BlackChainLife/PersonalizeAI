12:31:11,66 graphrag.config.read_dotenv INFO Loading pipeline .env file
12:31:11,71 graphrag.index.cli INFO using default configuration: {
    "llm": {
        "api_key": "REDACTED, length 56",
        "type": "openai_chat",
        "model": "gpt-4-turbo-preview",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://chatgptproxyapi-5uc.pages.dev/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": ".\\graphRAG_demo\\",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://chatgptproxyapi-5uc.pages.dev/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://chatgptproxyapi-5uc.pages.dev/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://chatgptproxyapi-5uc.pages.dev/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://chatgptproxyapi-5uc.pages.dev/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "REDACTED, length 56",
            "type": "openai_chat",
            "model": "gpt-4-turbo-preview",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://chatgptproxyapi-5uc.pages.dev/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
12:31:11,73 graphrag.index.create_pipeline_config INFO skipping workflows 
12:31:11,74 graphrag.index.run INFO Running pipeline
12:31:11,74 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at graphRAG_demo\output\20240729-123111\artifacts
12:31:11,75 graphrag.index.input.load_input INFO loading input from root_dir=input
12:31:11,76 graphrag.index.input.load_input INFO using file storage for input
12:31:11,76 graphrag.index.storage.file_pipeline_storage INFO search graphRAG_demo\input for files matching .*\.txt$
12:31:11,77 graphrag.index.input.text INFO found text files from input, found [('book.txt', {})]
12:31:11,80 graphrag.index.input.text INFO Found 1 files, loading 1
12:31:11,81 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
12:31:11,81 graphrag.index.run INFO Final # of rows loaded: 1
12:31:11,197 graphrag.index.run INFO Running workflow: create_base_text_units...
12:31:11,197 graphrag.index.run INFO dependencies for create_base_text_units: []
12:31:11,203 datashaper.workflow.workflow INFO executing verb orderby
12:31:11,206 datashaper.workflow.workflow INFO executing verb zip
12:31:11,209 datashaper.workflow.workflow INFO executing verb aggregate_override
12:31:11,214 datashaper.workflow.workflow INFO executing verb chunk
12:31:11,407 datashaper.workflow.workflow INFO executing verb select
12:31:11,412 datashaper.workflow.workflow INFO executing verb unroll
12:31:11,418 datashaper.workflow.workflow INFO executing verb rename
12:31:11,421 datashaper.workflow.workflow INFO executing verb genid
12:31:11,427 datashaper.workflow.workflow INFO executing verb unzip
12:31:11,432 datashaper.workflow.workflow INFO executing verb copy
12:31:11,437 datashaper.workflow.workflow INFO executing verb filter
12:31:11,448 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
12:31:11,614 graphrag.index.run INFO Running workflow: create_base_extracted_entities...
12:31:11,615 graphrag.index.run INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
12:31:11,615 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
12:31:11,631 datashaper.workflow.workflow INFO executing verb entity_extract
12:31:11,638 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://chatgptproxyapi-5uc.pages.dev/v1
12:31:12,495 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4-turbo-preview: TPM=0, RPM=0
12:31:12,495 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4-turbo-preview: 25
12:31:21,480 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:21,483 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.89000000001397. input_tokens=3134, output_tokens=224
12:31:22,704 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:22,706 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.125. input_tokens=3134, output_tokens=283
12:31:22,883 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:22,884 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.327999999979511. input_tokens=3132, output_tokens=272
12:31:23,564 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:23,565 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 11.01500000001397. input_tokens=3134, output_tokens=256
12:31:24,230 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:24,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 11.670999999972992. input_tokens=3133, output_tokens=323
12:31:24,833 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:24,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.23499999998603. input_tokens=3134, output_tokens=316
12:31:25,301 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:25,302 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.765999999945052. input_tokens=3134, output_tokens=367
12:31:25,354 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:25,355 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.827999999979511. input_tokens=3134, output_tokens=467
12:31:25,393 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:25,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 12.84299999999348. input_tokens=3134, output_tokens=372
12:31:25,998 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:25,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 13.452999999979511. input_tokens=3133, output_tokens=300
12:31:26,411 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:26,412 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 13.844000000040978. input_tokens=3134, output_tokens=351
12:31:26,717 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:26,722 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 14.202999999979511. input_tokens=3134, output_tokens=414
12:31:28,212 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:28,231 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.64000000001397. input_tokens=3133, output_tokens=409
12:31:28,493 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:28,498 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.891000000061467. input_tokens=3134, output_tokens=360
12:31:30,563 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:30,564 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 17.984000000054948. input_tokens=3134, output_tokens=502
12:31:31,254 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:31,259 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.68799999996554. input_tokens=3134, output_tokens=551
12:31:31,308 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:31,309 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 18.73499999998603. input_tokens=3134, output_tokens=490
12:31:33,307 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:33,309 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.73499999998603. input_tokens=3134, output_tokens=476
12:31:33,463 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:33,464 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.921999999904074. input_tokens=3134, output_tokens=481
12:31:34,60 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:34,62 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.515999999945052. input_tokens=3134, output_tokens=493
12:31:34,255 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:34,256 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.65700000000652. input_tokens=3134, output_tokens=596
12:31:34,407 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:34,408 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 9.109000000054948. input_tokens=3133, output_tokens=254
12:31:34,544 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:34,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.329000000027008. input_tokens=3133, output_tokens=294
12:31:34,795 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:34,807 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 13.329000000027008. input_tokens=3134, output_tokens=381
12:31:36,120 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:36,126 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.5. input_tokens=3133, output_tokens=672
12:31:36,380 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:36,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 23.765999999945052. input_tokens=3134, output_tokens=553
12:31:37,312 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:37,318 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 11.969000000040978. input_tokens=3135, output_tokens=347
12:31:38,176 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:38,177 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 11.765999999945052. input_tokens=3133, output_tokens=337
12:31:38,219 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:38,220 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.625. input_tokens=3134, output_tokens=590
12:31:38,307 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:38,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 14.73499999998603. input_tokens=3134, output_tokens=426
12:31:38,334 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:38,336 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 25.81299999996554. input_tokens=3132, output_tokens=718
12:31:38,612 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:38,613 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.047000000020489. input_tokens=3134, output_tokens=220
12:31:38,741 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:38,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 10.516000000061467. input_tokens=3133, output_tokens=253
12:31:39,298 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:39,299 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.047000000020489. input_tokens=3134, output_tokens=225
12:31:40,953 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:40,955 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.562999999965541. input_tokens=3134, output_tokens=443
12:31:42,318 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:42,323 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 13.827999999979511. input_tokens=3134, output_tokens=340
12:31:43,790 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:43,793 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 7.406000000075437. input_tokens=19, output_tokens=224
12:31:44,293 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:44,298 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 21.594000000040978. input_tokens=3134, output_tokens=595
12:31:44,708 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:44,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 5.968999999924563. input_tokens=19, output_tokens=127
12:31:45,91 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:45,98 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.26500000001397. input_tokens=3134, output_tokens=364
12:31:47,575 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:47,576 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.844000000040978. input_tokens=3133, output_tokens=638
12:31:48,65 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:48,71 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 16.76500000001397. input_tokens=2987, output_tokens=372
12:31:48,154 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:48,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 8.84299999999348. input_tokens=19, output_tokens=231
12:31:49,66 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:49,74 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 26.18700000003446. input_tokens=3134, output_tokens=531
12:31:50,975 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:50,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 24.983999999938533. input_tokens=3134, output_tokens=537
12:31:51,460 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:51,462 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.75. input_tokens=19, output_tokens=166
12:31:52,177 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:52,178 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 18.875. input_tokens=19, output_tokens=518
12:31:52,818 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:52,826 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 18.56200000003446. input_tokens=19, output_tokens=525
12:31:54,789 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:54,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.234000000054948. input_tokens=19, output_tokens=567
12:31:55,558 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:55,560 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.75. input_tokens=19, output_tokens=587
12:31:56,423 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:56,424 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 8.28200000000652. input_tokens=19, output_tokens=245
12:31:56,645 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:56,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.51500000001397. input_tokens=19, output_tokens=607
12:31:57,906 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:57,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 23.859000000054948. input_tokens=19, output_tokens=723
12:31:58,87 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:58,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 19.905999999959022. input_tokens=19, output_tokens=597
12:31:58,117 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:58,118 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 23.70299999997951. input_tokens=19, output_tokens=732
12:31:59,821 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:31:59,822 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 26.359000000054948. input_tokens=19, output_tokens=636
12:32:00,77 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:00,81 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 21.780999999959022. input_tokens=19, output_tokens=665
12:32:01,206 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:01,213 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.875. input_tokens=19, output_tokens=678
12:32:02,765 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:02,767 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 17.67200000002049. input_tokens=19, output_tokens=587
12:32:02,798 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:02,799 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 24.18799999996554. input_tokens=19, output_tokens=748
12:32:03,845 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:03,847 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.89000000001397. input_tokens=19, output_tokens=673
12:32:05,211 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:05,213 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 20.905999999959022. input_tokens=19, output_tokens=529
12:32:05,514 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:05,515 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 10.718999999924563. input_tokens=19, output_tokens=259
12:32:07,744 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:07,752 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 25.43799999996554. input_tokens=19, output_tokens=792
12:32:09,941 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:09,943 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 17.76500000001397. input_tokens=19, output_tokens=568
12:32:10,128 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:10,129 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 13.48499999998603. input_tokens=19, output_tokens=401
12:32:10,638 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:10,639 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 21.56299999996554. input_tokens=19, output_tokens=681
12:32:10,765 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:10,766 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.70299999997951. input_tokens=19, output_tokens=712
12:32:11,692 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:11,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 18.875. input_tokens=19, output_tokens=597
12:32:11,980 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:11,982 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 33.75. input_tokens=19, output_tokens=861
12:32:11,994 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:12,1 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 14.093999999924563. input_tokens=19, output_tokens=501
12:32:12,512 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:12,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 21.04700000002049. input_tokens=19, output_tokens=654
12:32:12,697 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:12,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 21.719000000040978. input_tokens=19, output_tokens=689
12:32:13,798 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:13,806 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 30.015999999945052. input_tokens=19, output_tokens=916
12:32:14,968 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:14,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 27.405999999959022. input_tokens=19, output_tokens=719
12:32:15,583 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:15,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 38.26599999994505. input_tokens=19, output_tokens=980
12:32:19,171 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:19,173 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 22.75. input_tokens=19, output_tokens=604
12:32:24,271 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:24,276 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 28.71799999999348. input_tokens=19, output_tokens=742
12:32:24,380 datashaper.workflow.workflow INFO executing verb merge_graphs
12:32:24,415 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
12:32:24,558 graphrag.index.run INFO Running workflow: create_summarized_entities...
12:32:24,558 graphrag.index.run INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
12:32:24,559 graphrag.index.run INFO read table from storage: create_base_extracted_entities.parquet
12:32:24,574 datashaper.workflow.workflow INFO executing verb summarize_descriptions
12:32:29,244 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:29,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.547000000020489. input_tokens=174, output_tokens=59
12:32:30,214 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:30,215 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.562999999965541. input_tokens=186, output_tokens=84
12:32:30,738 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:30,739 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.094000000040978. input_tokens=204, output_tokens=102
12:32:30,753 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:30,754 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.10999999998603. input_tokens=302, output_tokens=169
12:32:30,838 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:30,839 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.140999999945052. input_tokens=206, output_tokens=111
12:32:30,889 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:30,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.23499999998603. input_tokens=189, output_tokens=105
12:32:31,620 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:31,626 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.952999999979511. input_tokens=203, output_tokens=128
12:32:32,704 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:32,710 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.015999999945052. input_tokens=300, output_tokens=125
12:32:32,747 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:32,748 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.077999999979511. input_tokens=280, output_tokens=159
12:32:32,962 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:32,963 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.312999999965541. input_tokens=215, output_tokens=130
12:32:32,986 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:32,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.327999999979511. input_tokens=526, output_tokens=173
12:32:33,158 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:33,160 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.484000000054948. input_tokens=279, output_tokens=176
12:32:33,182 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:33,183 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.48499999998603. input_tokens=390, output_tokens=175
12:32:33,437 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:33,438 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.187999999965541. input_tokens=188, output_tokens=99
12:32:33,991 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:33,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.297000000020489. input_tokens=426, output_tokens=195
12:32:34,27 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:34,30 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.187000000034459. input_tokens=185, output_tokens=78
12:32:34,369 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:34,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.156000000075437. input_tokens=235, output_tokens=106
12:32:34,951 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:34,952 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.26500000001397. input_tokens=633, output_tokens=229
12:32:35,114 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:35,119 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.422000000020489. input_tokens=489, output_tokens=236
12:32:35,614 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:35,615 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.906000000075437. input_tokens=305, output_tokens=242
12:32:35,670 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:35,671 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.9530000000959262. input_tokens=154, output_tokens=56
12:32:35,816 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:35,822 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 11.155999999959022. input_tokens=934, output_tokens=210
12:32:35,953 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:35,954 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.062000000034459. input_tokens=180, output_tokens=79
12:32:35,980 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:35,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.342999999993481. input_tokens=178, output_tokens=71
12:32:36,144 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:36,148 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 11.483999999938533. input_tokens=590, output_tokens=258
12:32:36,385 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:36,385 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.422000000020489. input_tokens=187, output_tokens=85
12:32:36,898 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:36,899 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.905999999959022. input_tokens=196, output_tokens=96
12:32:36,978 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:36,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.6089999999385327. input_tokens=194, output_tokens=58
12:32:36,995 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:37,0 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 12.327999999979511. input_tokens=963, output_tokens=294
12:32:37,229 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:37,232 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.045999999972992. input_tokens=181, output_tokens=81
12:32:37,658 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:37,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 12.984000000054948. input_tokens=712, output_tokens=236
12:32:37,791 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:37,795 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.031000000075437. input_tokens=187, output_tokens=126
12:32:38,608 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:38,608 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.608999999938533. input_tokens=165, output_tokens=87
12:32:38,741 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:38,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.0. input_tokens=233, output_tokens=127
12:32:39,328 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:39,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.687999999965541. input_tokens=801, output_tokens=287
12:32:39,438 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:39,439 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.765999999945052. input_tokens=572, output_tokens=280
12:32:40,436 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:40,437 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.75. input_tokens=728, output_tokens=364
12:32:40,645 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:40,646 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.702999999979511. input_tokens=202, output_tokens=122
12:32:41,10 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:41,11 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.98499999998603. input_tokens=200, output_tokens=87
12:32:41,102 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:41,103 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.936999999918044. input_tokens=182, output_tokens=103
12:32:41,928 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:41,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.5. input_tokens=236, output_tokens=126
12:32:41,994 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:41,995 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 17.32799999997951. input_tokens=1333, output_tokens=450
12:32:42,342 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:42,343 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 11.593999999924563. input_tokens=323, output_tokens=261
12:32:42,374 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:42,375 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.265999999945052. input_tokens=215, output_tokens=109
12:32:42,770 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:42,771 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.983999999938533. input_tokens=235, output_tokens=127
12:32:42,828 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:42,833 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.452999999979511. input_tokens=453, output_tokens=166
12:32:43,569 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:43,576 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.125. input_tokens=185, output_tokens=76
12:32:43,879 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:43,880 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.657000000006519. input_tokens=182, output_tokens=122
12:32:44,223 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:44,227 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.577999999979511. input_tokens=185, output_tokens=82
12:32:44,277 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:44,278 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.26500000001397. input_tokens=235, output_tokens=171
12:32:44,412 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:44,414 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.266000000061467. input_tokens=520, output_tokens=247
12:32:44,819 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:44,820 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 7.844000000040978. input_tokens=512, output_tokens=224
12:32:45,255 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:45,256 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.28200000000652. input_tokens=474, output_tokens=221
12:32:45,325 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:45,326 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.702999999979511. input_tokens=623, output_tokens=247
12:32:45,412 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:45,413 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 9.594000000040978. input_tokens=275, output_tokens=189
12:32:45,479 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:45,480 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.702999999979511. input_tokens=178, output_tokens=58
12:32:45,545 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:45,552 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.172000000020489. input_tokens=188, output_tokens=72
12:32:45,724 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:45,728 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 3.7959999999729916. input_tokens=199, output_tokens=86
12:32:46,306 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:46,307 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.875. input_tokens=254, output_tokens=144
12:32:46,752 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:46,753 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.657000000006519. input_tokens=212, output_tokens=113
12:32:46,861 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:46,862 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.125. input_tokens=423, output_tokens=253
12:32:47,217 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:47,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.202999999979511. input_tokens=223, output_tokens=155
12:32:47,645 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:47,647 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 5.312000000034459. input_tokens=235, output_tokens=132
12:32:48,737 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:48,743 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.75. input_tokens=264, output_tokens=196
12:32:49,258 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:49,259 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 13.297000000020489. input_tokens=871, output_tokens=331
12:32:49,936 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:49,937 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.594000000040978. input_tokens=454, output_tokens=298
12:32:49,964 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:49,965 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.296999999904074. input_tokens=448, output_tokens=369
12:32:49,985 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:49,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 11.391000000061467. input_tokens=415, output_tokens=279
12:32:51,999 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:52,4 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.10999999998603. input_tokens=765, output_tokens=348
12:32:52,259 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:32:52,267 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 14.608999999938533. input_tokens=769, output_tokens=387
12:32:52,291 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
12:32:52,430 graphrag.index.run INFO Running workflow: create_base_entity_graph...
12:32:52,430 graphrag.index.run INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
12:32:52,430 graphrag.index.run INFO read table from storage: create_summarized_entities.parquet
12:32:52,445 datashaper.workflow.workflow INFO executing verb cluster_graph
12:32:52,521 datashaper.workflow.workflow INFO executing verb select
12:32:52,524 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
12:32:52,665 graphrag.index.run INFO Running workflow: create_final_entities...
12:32:52,665 graphrag.index.run INFO dependencies for create_final_entities: ['create_base_entity_graph']
12:32:52,665 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:32:52,685 datashaper.workflow.workflow INFO executing verb unpack_graph
12:32:52,714 datashaper.workflow.workflow INFO executing verb rename
12:32:52,723 datashaper.workflow.workflow INFO executing verb select
12:32:52,732 datashaper.workflow.workflow INFO executing verb dedupe
12:32:52,741 datashaper.workflow.workflow INFO executing verb rename
12:32:52,750 datashaper.workflow.workflow INFO executing verb filter
12:32:52,772 datashaper.workflow.workflow INFO executing verb text_split
12:32:52,783 datashaper.workflow.workflow INFO executing verb drop
12:32:52,793 datashaper.workflow.workflow INFO executing verb merge
12:32:52,833 datashaper.workflow.workflow INFO executing verb text_embed
12:32:52,834 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=https://chatgptproxyapi-5uc.pages.dev/v1
12:32:53,705 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
12:32:53,705 graphrag.index.llm.load_llm INFO create concurrency limiter for text-embedding-3-small: 25
12:32:53,724 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 171 inputs via 171 snippets using 11 batches. max_batch_size=16, max_tokens=8191
12:32:54,637 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,642 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,654 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,666 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,667 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,673 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,679 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,684 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,726 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,728 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:54,741 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/embeddings "HTTP/1.1 200 OK"
12:32:55,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.375. input_tokens=279, output_tokens=0
12:32:55,166 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.422000000020489. input_tokens=923, output_tokens=0
12:32:55,185 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4540000000270084. input_tokens=1416, output_tokens=0
12:32:55,206 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4689999999245629. input_tokens=627, output_tokens=0
12:32:55,224 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5. input_tokens=3188, output_tokens=0
12:32:55,241 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5160000000614673. input_tokens=1037, output_tokens=0
12:32:55,259 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.515999999945052. input_tokens=729, output_tokens=0
12:32:55,275 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5309999999590218. input_tokens=770, output_tokens=0
12:32:55,293 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.547000000020489. input_tokens=614, output_tokens=0
12:32:55,311 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.562999999965541. input_tokens=501, output_tokens=0
12:32:55,328 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5940000000409782. input_tokens=1225, output_tokens=0
12:32:55,385 datashaper.workflow.workflow INFO executing verb drop
12:32:55,395 datashaper.workflow.workflow INFO executing verb filter
12:32:55,411 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
12:32:55,603 graphrag.index.run INFO Running workflow: create_final_nodes...
12:32:55,603 graphrag.index.run INFO dependencies for create_final_nodes: ['create_base_entity_graph']
12:32:55,603 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:32:55,628 datashaper.workflow.workflow INFO executing verb layout_graph
12:32:55,723 datashaper.workflow.workflow INFO executing verb unpack_graph
12:32:55,759 datashaper.workflow.workflow INFO executing verb unpack_graph
12:32:55,795 datashaper.workflow.workflow INFO executing verb drop
12:32:55,807 datashaper.workflow.workflow INFO executing verb filter
12:32:55,839 datashaper.workflow.workflow INFO executing verb select
12:32:55,852 datashaper.workflow.workflow INFO executing verb rename
12:32:55,864 datashaper.workflow.workflow INFO executing verb convert
12:32:55,905 datashaper.workflow.workflow INFO executing verb join
12:32:55,924 datashaper.workflow.workflow INFO executing verb rename
12:32:55,926 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
12:32:56,85 graphrag.index.run INFO Running workflow: create_final_communities...
12:32:56,85 graphrag.index.run INFO dependencies for create_final_communities: ['create_base_entity_graph']
12:32:56,86 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:32:56,115 datashaper.workflow.workflow INFO executing verb unpack_graph
12:32:56,150 datashaper.workflow.workflow INFO executing verb unpack_graph
12:32:56,184 datashaper.workflow.workflow INFO executing verb aggregate_override
12:32:56,200 datashaper.workflow.workflow INFO executing verb join
12:32:56,220 datashaper.workflow.workflow INFO executing verb join
12:32:56,241 datashaper.workflow.workflow INFO executing verb concat
12:32:56,254 datashaper.workflow.workflow INFO executing verb filter
12:32:56,321 datashaper.workflow.workflow INFO executing verb aggregate_override
12:32:56,340 datashaper.workflow.workflow INFO executing verb join
12:32:56,361 datashaper.workflow.workflow INFO executing verb filter
12:32:56,412 datashaper.workflow.workflow INFO executing verb fill
12:32:56,428 datashaper.workflow.workflow INFO executing verb merge
12:32:56,449 datashaper.workflow.workflow INFO executing verb copy
12:32:56,465 datashaper.workflow.workflow INFO executing verb select
12:32:56,467 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
12:32:56,642 graphrag.index.run INFO Running workflow: join_text_units_to_entity_ids...
12:32:56,642 graphrag.index.run INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
12:32:56,642 graphrag.index.run INFO read table from storage: create_final_entities.parquet
12:32:56,689 datashaper.workflow.workflow INFO executing verb select
12:32:56,707 datashaper.workflow.workflow INFO executing verb unroll
12:32:56,727 datashaper.workflow.workflow INFO executing verb aggregate_override
12:32:56,732 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
12:32:56,909 graphrag.index.run INFO Running workflow: create_final_relationships...
12:32:56,909 graphrag.index.run INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
12:32:56,910 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
12:32:56,916 graphrag.index.run INFO read table from storage: create_base_entity_graph.parquet
12:32:56,956 datashaper.workflow.workflow INFO executing verb unpack_graph
12:32:56,996 datashaper.workflow.workflow INFO executing verb filter
12:32:57,40 datashaper.workflow.workflow INFO executing verb rename
12:32:57,59 datashaper.workflow.workflow INFO executing verb filter
12:32:57,103 datashaper.workflow.workflow INFO executing verb drop
12:32:57,122 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
12:32:57,145 datashaper.workflow.workflow INFO executing verb convert
12:32:57,186 datashaper.workflow.workflow INFO executing verb convert
12:32:57,188 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
12:32:57,363 graphrag.index.run INFO Running workflow: join_text_units_to_relationship_ids...
12:32:57,364 graphrag.index.run INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
12:32:57,364 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
12:32:57,407 datashaper.workflow.workflow INFO executing verb select
12:32:57,447 datashaper.workflow.workflow INFO executing verb unroll
12:32:57,469 datashaper.workflow.workflow INFO executing verb aggregate_override
12:32:57,493 datashaper.workflow.workflow INFO executing verb select
12:32:57,495 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
12:32:57,698 graphrag.index.run INFO Running workflow: create_final_community_reports...
12:32:57,698 graphrag.index.run INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
12:32:57,699 graphrag.index.run INFO read table from storage: create_final_relationships.parquet
12:32:57,703 graphrag.index.run INFO read table from storage: create_final_nodes.parquet
12:32:57,749 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
12:32:57,776 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
12:32:57,800 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
12:32:57,826 datashaper.workflow.workflow INFO executing verb prepare_community_reports
12:32:57,827 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=2 => 171
12:32:57,873 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=1 => 171
12:32:57,945 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 171
12:32:58,17 datashaper.workflow.workflow INFO executing verb create_community_reports
12:33:22,476 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:33:22,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 24.436999999918044. input_tokens=2992, output_tokens=794
12:33:35,787 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:33:35,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 37.75. input_tokens=14591, output_tokens=919
12:34:00,514 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:00,516 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 24.67200000002049. input_tokens=2742, output_tokens=750
12:34:00,882 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:00,883 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 25.015999999945052. input_tokens=2560, output_tokens=740
12:34:01,414 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:01,418 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 25.594000000040978. input_tokens=2690, output_tokens=567
12:34:02,14 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:02,16 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 26.15700000000652. input_tokens=3132, output_tokens=813
12:34:03,214 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:03,216 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 27.375. input_tokens=2782, output_tokens=866
12:34:03,828 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:03,829 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 28.015999999945052. input_tokens=4062, output_tokens=772
12:34:06,646 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:06,647 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 30.780999999959022. input_tokens=15203, output_tokens=894
12:34:08,65 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:08,66 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 32.21900000004098. input_tokens=4387, output_tokens=900
12:34:12,74 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:12,76 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 36.23400000005495. input_tokens=2800, output_tokens=789
12:34:26,249 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:26,250 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 14.094000000040978. input_tokens=2098, output_tokens=462
12:34:30,459 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:30,461 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 18.343999999924563. input_tokens=2417, output_tokens=642
12:34:31,180 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:31,181 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 19.03200000000652. input_tokens=2312, output_tokens=501
12:34:32,823 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:32,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 20.70299999997951. input_tokens=3441, output_tokens=748
12:34:35,172 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:35,173 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 23.04700000002049. input_tokens=4712, output_tokens=852
12:34:38,365 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:38,366 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 26.266000000061467. input_tokens=2804, output_tokens=741
12:34:41,476 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:41,481 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 29.32799999997951. input_tokens=5397, output_tokens=813
12:34:54,438 httpx INFO HTTP Request: POST https://chatgptproxyapi-5uc.pages.dev/v1/chat/completions "HTTP/1.1 200 OK"
12:34:54,444 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 42.31200000003446. input_tokens=15927, output_tokens=1005
12:34:54,493 datashaper.workflow.workflow INFO executing verb window
12:34:54,496 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
12:34:54,710 graphrag.index.run INFO Running workflow: create_final_text_units...
12:34:54,719 graphrag.index.run INFO dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids']
12:34:54,720 graphrag.index.run INFO read table from storage: create_base_text_units.parquet
12:34:54,724 graphrag.index.run INFO read table from storage: join_text_units_to_entity_ids.parquet
12:34:54,728 graphrag.index.run INFO read table from storage: join_text_units_to_relationship_ids.parquet
12:34:54,783 datashaper.workflow.workflow INFO executing verb select
12:34:54,809 datashaper.workflow.workflow INFO executing verb rename
12:34:54,834 datashaper.workflow.workflow INFO executing verb join
12:34:54,864 datashaper.workflow.workflow INFO executing verb join
12:34:54,899 datashaper.workflow.workflow INFO executing verb aggregate_override
12:34:54,928 datashaper.workflow.workflow INFO executing verb select
12:34:54,930 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
12:34:55,132 graphrag.index.run INFO Running workflow: create_base_documents...
12:34:55,132 graphrag.index.run INFO dependencies for create_base_documents: ['create_final_text_units']
12:34:55,133 graphrag.index.run INFO read table from storage: create_final_text_units.parquet
12:34:55,187 datashaper.workflow.workflow INFO executing verb unroll
12:34:55,215 datashaper.workflow.workflow INFO executing verb select
12:34:55,240 datashaper.workflow.workflow INFO executing verb rename
12:34:55,266 datashaper.workflow.workflow INFO executing verb join
12:34:55,295 datashaper.workflow.workflow INFO executing verb aggregate_override
12:34:55,323 datashaper.workflow.workflow INFO executing verb join
12:34:55,353 datashaper.workflow.workflow INFO executing verb rename
12:34:55,380 datashaper.workflow.workflow INFO executing verb convert
12:34:55,436 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
12:34:55,614 graphrag.index.run INFO Running workflow: create_final_documents...
12:34:55,614 graphrag.index.run INFO dependencies for create_final_documents: ['create_base_documents']
12:34:55,615 graphrag.index.run INFO read table from storage: create_base_documents.parquet
12:34:55,672 datashaper.workflow.workflow INFO executing verb rename
12:34:55,674 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
